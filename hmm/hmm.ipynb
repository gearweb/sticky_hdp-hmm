{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Baum Welch Algorithm](http://www.adeveloperdiary.com/data-science/machine-learning/derivation-and-implementation-of-baum-welch-algorithm-for-hidden-markov-model/)<br/>\n",
    "[Code](https://github.com/adeveloperdiary/HiddenMarkovModel/tree/master/part3)\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "{'a': array([[0.53816345, 0.46183655],\n       [0.48664443, 0.51335557]]), 'b': array([[0.16277513, 0.26258073, 0.57464414],\n       [0.2514996 , 0.27780971, 0.47069069]])}\n"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    " \n",
    " \n",
    "def forward(V, a, b, initial_distribution):\n",
    "    alpha = np.zeros((V.shape[0], a.shape[0]))\n",
    "    alpha[0, :] = initial_distribution * b[:, V[0]]\n",
    " \n",
    "    for t in range(1, V.shape[0]):\n",
    "        for j in range(a.shape[0]):\n",
    "            # Matrix Computation Steps\n",
    "            #                  ((1x2) . (1x2))      *     (1)\n",
    "            #                        (1)            *     (1)\n",
    "            alpha[t, j] = alpha[t - 1].dot(a[:, j]) * b[j, V[t]]\n",
    " \n",
    "    return alpha\n",
    " \n",
    " \n",
    "def backward(V, a, b):\n",
    "    beta = np.zeros((V.shape[0], a.shape[0]))\n",
    " \n",
    "    # setting beta(T) = 1\n",
    "    beta[V.shape[0] - 1] = np.ones((a.shape[0]))\n",
    " \n",
    "    # Loop in backward way from T-1 to\n",
    "    # Due to python indexing the actual loop will be T-2 to 0\n",
    "    for t in range(V.shape[0] - 2, -1, -1):\n",
    "        for j in range(a.shape[0]):\n",
    "            beta[t, j] = (beta[t + 1] * b[:, V[t + 1]]).dot(a[j, :])\n",
    " \n",
    "    return beta\n",
    " \n",
    " \n",
    "def baum_welch(V, a, b, initial_distribution, n_iter=100):\n",
    "    M = a.shape[0]\n",
    "    T = len(V)\n",
    " \n",
    "    for n in range(n_iter):\n",
    "        alpha = forward(V, a, b, initial_distribution)\n",
    "        beta = backward(V, a, b)\n",
    " \n",
    "        xi = np.zeros((M, M, T - 1))\n",
    "        for t in range(T - 1):\n",
    "            denominator = np.dot(np.dot(alpha[t, :].T, a) * b[:, V[t + 1]].T, beta[t + 1, :])\n",
    "            for i in range(M):\n",
    "                numerator = alpha[t, i] * a[i, :] * b[:, V[t + 1]].T * beta[t + 1, :].T\n",
    "                xi[i, :, t] = numerator / denominator\n",
    " \n",
    "        gamma = np.sum(xi, axis=1)\n",
    "        a = np.sum(xi, 2) / np.sum(gamma, axis=1).reshape((-1, 1))\n",
    " \n",
    "        # Add additional T'th element in gamma\n",
    "        gamma = np.hstack((gamma, np.sum(xi[:, :, T - 2], axis=0).reshape((-1, 1))))\n",
    " \n",
    "        K = b.shape[1]\n",
    "        denominator = np.sum(gamma, axis=1)\n",
    "        for l in range(K):\n",
    "            b[:, l] = np.sum(gamma[:, V == l], axis=1)\n",
    " \n",
    "        b = np.divide(b, denominator.reshape((-1, 1)))\n",
    " \n",
    "    return {\"a\":a, \"b\":b}\n",
    " \n",
    " \n",
    "data = pd.read_csv('data_python.csv')\n",
    " \n",
    "V = data['Visible'].values\n",
    " \n",
    "# Transition Probabilities\n",
    "a = np.ones((2, 2))\n",
    "a = a / np.sum(a, axis=1)\n",
    "\n",
    " \n",
    "# Emission Probabilities\n",
    "b = np.array(((1, 3, 5), (2, 4, 6)))\n",
    "b = b / np.sum(b, axis=1).reshape((-1, 1))\n",
    " \n",
    "# Equal Probabilities for the initial distribution of the states\n",
    "initial_distribution = np.array((0.5, 0.5))\n",
    " \n",
    "print(baum_welch(V, a, b, initial_distribution, n_iter=100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a: transmission matrix</br>\n",
    "b: emissions matrix\n",
    "```\n",
    "{\n",
    "    'a': array([[0.53816345, 0.46183655],\n",
    "                [0.48664443, 0.51335557]]), \n",
    "    'b': array([[0.16277513, 0.26258073, 0.57464414],\n",
    "                [0.2514996 , 0.27780971, 0.47069069]])\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared with R statistics output\n",
    "```\n",
    "library(HMM)\n",
    "hmm =initHMM(c(\"A\", \"B\"), c(1, 2, 3), \n",
    "              startProbs = initial_distribution,\n",
    "              transProbs = A, emissionProbs = B)\n",
    " \n",
    "true.out = baumWelch(hmm, data$Visible, maxIterations=100, pseudoCount=0)\n",
    "true.out$hmm\n",
    "                     \n",
    "States\n",
    "[1] \"A\" \"B\"\n",
    " \n",
    "$Symbols\n",
    "[1] 1 2 3\n",
    " \n",
    "$startProbs\n",
    "  A   B \n",
    "0.5 0.5 \n",
    " \n",
    "$transProbs\n",
    "    to\n",
    "from         A         B\n",
    "   A 0.5381634 0.4618366\n",
    "   B 0.4866444 0.5133556\n",
    " \n",
    "$emissionProbs\n",
    "      symbols\n",
    "states         1         2         3\n",
    "     A 0.1627751 0.2625807 0.5746441\n",
    "     B 0.2514996 0.2778097 0.4706907\n",
    "```\n",
    "                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}